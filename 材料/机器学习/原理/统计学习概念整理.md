# 统计学习概念整理


## 1.1 先验概率

这个词在机器学习领域中经常出现，但是它的理解却比较复杂。我搜集了许多资料，至少看到了两种解读方式。

我们先一种一种来说，百度百科当中对于先验概率的定义为：

>先验概率（prior probability）是指根据以往经验和分析得到的概率，如全概率公式，它往往作为"由因求果"问题中的"因"出现的概率。

维基百科中的说法就要玄妙很多，理解起来也会困难很多：

>某一不确定量p的**先验概率**（Prior probability）分布是在考虑“观测数据”前，能表达p不确定性的概率分布。它旨在描述这个不确定量的不确定程度，而不是这个不确定量的随机性。这个不确定量可以是一个参数，或者是一个隐含变量（英语：latent variable）。依据应用领域的不同，先验概率又叫做先验概率、先验概率、事前先验概率、居先概率。

这段话非常拗口，但是它的核心意思是说，先验概率表达的是变量的不确定程度，而不是变量的随机性。结合我们上面百度百科的定义，我们可以给出一个模糊的理解：先验概率是一个先于观测/实验，根据经验或以往数据分析得到的一个“全局”概率，它表达的是变量本身的一个不确定程度。

举个例子，比如过去10天，有2天下雨。那么每一天会下雨的概率是0.2，但假如我们从其他角度入手，比如说对云层厚度进行分析之后，对于明天要下雨的概率有了一个新的猜测p。

那么明天到底下不下雨呢？我们可以比较0.2p和0.8(1-p)的大小，来判断明天会不会下雨。为什么p要乘上0.2？因为0.2是全局可能下雨的概率，是一个全局的影响，是一个前提条件，有点像是实验背景加上的buff。

## 1.2 后验概率

要说后验概率，就不得不提贝叶斯定理，这两者是相辅相成的。

我们同样先来看看百科当中的定义，首先是百度百科：

>后验概率的计算要以先验概率为基础。后验概率可以根据通过贝叶斯公式，用先验概率和似然函数计算出来.

再是维基百科：

>在贝叶斯统计中，一个随机事件或者一个不确定事件的后验概率（Posterior probability）是在考虑和给出相关证据或数据后所得到的条件概率。同样，后验概率分布是一个未知量（视为随机变量）基于试验和调查后得到的概率分布。“后验”在本文中代表考虑了被测试事件的相关证据。

哇，这两者看起来都不是省油的灯，没有一个好理解的。但是它们都提到了一点，就是贝叶斯。在列出贝叶斯公式之前，我们先来聊聊贝叶斯定理究竟是干什么的。

这个问题很简单，它只做了一件事，就是寻果溯因，也就是根据结果猜测原因。因为结果是可以观测的，而原因没办法猜测。我们抬头看一眼就知道有没有下雨，但是为什么下雨就没办法通过观察得到了。

要分析原因，就要用到贝叶斯定理了。贝叶斯定理虽然简单但是应用方面非常广泛，最大的原因就是它搭建了一个计算后验概率，也就是寻找原因的方法。

我们假设今天下雨是事件X，明天下雨是事件Y。P(X)表示今天下雨的概率，P(Y)表示明天下雨的概率，P(Y|X)表示今天下雨的前提下明天下雨的概率，这些都是可以通过历史数据计算得到的。然而当我们要求原因的时候，需要的是P(X|Y)。这个时候就需要套用贝叶斯公式了：

$$P(X|Y)=\frac{P(Y|X)*P(X)}{P(Y)}$$

我们会发现P(X),P(Y),P(Y|X)这三个都是先验概率，也就是说都是可以通过观测和计算得到的，计算出了一个原本没办法直接求的概率。


## 1.3 似然
似然这个词也经常出现，比如什么似然函数，极大似然估计等等。

似然本身并非很复杂的概念，但由于关于概率的概念非常多，什么条件概率，先验概率，后验概率等等混杂在一起，非常具有迷惑性。我自己也很长一段时间里没有完全搞明白，后来直到有一次我注意到了似然这个词的英文是likelihood，这不就是可能性的意思吗？

后来一查词典，果然如此。在英文语境当中，似然（likelihood）和概率（probability）是近义词，都是指可能性的意思。但是在数学领域，两者是有严格区分的，其中概率求的是已经知道参数$\theta$，事件X发生的概率，也就是$P(X|\theta)$。而似然侧重事件A发生时它的原因是$\theta$的概率，求的是$L(\theta|X)$,这不和后验概率差不多么？







