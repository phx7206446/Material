
在决策树剪枝方法中有一个悲观错误剪枝法，这里面最重要的一个思想，就是从离散到连续的修正，这时候用到一个值 0.5。

这本文章主要给出了该做法的具体原理和依据。


# 1. 什么是二项分布？
![[b46b76015c7c7575f54b2b00701bbc97 1.jpg]]

我们先通过投硬币的小游戏来说明什么是二项分布。

把硬币弹起来，落入手中，紧紧扣死，问对面的小伙伴：“你猜猜现在硬币是正面朝上，还是反面朝上呢？”

这种只有两个结果的小试验，就是伯努利试验，这是为了纪念瑞士的科学家Jacob Bernoulli 而命名的。

那么，只有两种结果的随机变量，与之相伴的分布就是伯努利分布。现在讲究的是量化，我们不妨将这个结果数字化表示，正面朝上记为1，反面朝上记为0，相应的概率就可以表达为：
$$ L(Y,f(X))=\begin{cases} 1-p, & X=0  \\ p, & X=1 \end{cases}$$
其中$0 \lt p \lt 1$,表示硬币正面朝上的概率。

不过聪明的小伙伴，肯定也发现了，由于只有两个结果，如果将上面这个分布画个图的话，就是下面这个样子，只有两个点是有值的，所以这个分布也被大家亲切地称作两点分布。

![[88606d085ac98e3560adfb11da140a69.jpg]]

很明显，在两点分布的世界中，非黑即白，是非分明。

![[db74a0551333b7a1dbf8a450c06628cf.jpg]]

啰嗦了这么久，可能有些小伙伴着急了，两点分布和二项分布有什么关系呢？

其实呢，二项分布就是把刚才我们所说的伯努利实验重复个$n$次，数一数正面朝上的次数，作为结果，以这个结果作为随机变量，服从的就是二项分布啦。
$$P(X=k)=C_n^kp^k(1-p)^{n-k},k=0,1,...,n.$$

看得出来，这个分布由两个参数决定，一个是重复试验的次数$n$，一个就是正面朝上的概率$p$，因此，二项分布（Binomial Distribution）用符号表示，就是$B(n,p)$。

那么显然，当$n=1$的时候，对应的就是伯努利分布$B(1,p)$

特别的，如果每次实验，两种结果是等概率出现的，也就是$p=0.5$，那么$P(X=k)$的大小就取决于组合数$C_n^k$的大小，我们可以画个杨辉三角来看一下。

![[ce283a66e2f2f8f8e9614db5abba2426.jpg]]

荧光黄标记的地方就是取最大值的位置，也就是说，当位于中间位置时，概率达到最大。

当然，杨辉三角中还隐藏着一串神奇的序列，就是斐波那契数列，感兴趣的小伙伴可以搜一搜哦。

言归正传，回到二项分布。  

二项分布的期望和方差，很容易根据定义求出来。

期望：
$$E(X)=\sum_{k=0}^nkC_n^kp^k(1-p)^{n-k}=np$$
方差：
$$Var(X)=E(X^2)-[E(X)]^2=np(1-p)$$
## 2. 从二项分布到正态分布

下面，为了方便演示，还是取$0.5$的“正面朝上”概率。

保持$p$不变，逐渐增大之间的试验次数$n$，绘制一下概率曲线，我们来看看会发生什么情况。

![[微信图片_20220531191028.gif]]

原来随着$n$的增大，二项分布的棱棱角角就逐渐被磨平了，当试验次数无穷大的时候，变成一条光滑的概率密度曲线，是不是很有意思?

是的，这就是从有限到无限，从离散到连续的变化过程。

这条光滑的概率密度曲线，对应的分布就是正态分布。

当然，除了直接做试验可以得到这样的结论。还有个定理也说明了同样的事情，这可是概率伦历史上的第一个中心极限定理，堪称鼻祖级别的——棣莫弗-拉普拉斯中心极限定理。

因为二项分布的极限分布是正态分布这个事儿，起初就是棣莫弗发现的。

>棣莫弗-拉普拉斯中心极限定理
>假设$n$重伯努利试验中，事件$A$在每次试验中出现的概率为$p$，记$S_n$为$n$次试验中事件$A$出现的次数，
>$$Y_n^{*}=\frac{S_n-np}{\sqrt{npq}}$$
>则对任意实数$y$,有
>$$lim_{n->\infty}P(Y_n^{*}\le y)=\int_{-\infty}^y\frac{1}{\sqrt{2\pi}}e^{- \frac{t^2}{2}dt}$$

对公式敏感的小伙伴应该能发现，
$$\frac{1}{\sqrt{2\pi}}e^{-\frac{t^2}{2}}$$
就是正态分布的概率密度函数。

那么，这个定理是什么含义呢？

这里解释一下：

这就是说，当试验次数足够多的时候，$S_n$所服从的分布就从二项分布$B(n,p)$变成$N(np,np(1-p))$了，这其中蕴含的就是频率学派确定概率的思想。

不过，很幸运的是分布的期望和方差并没有发生变化，依然是$np$和$np(1-p)$

## 3. 离散到连续的修正

什么时候才能用连续性修正呢？

当二项分布的期望$np$大到可以用正态分布近似的时候！

什么时候才是达到可以用正态分布近似呢？

比如$np\gt 5$ 和 $n(1-p)\gt5$ 的时候，就可以啦。

下面我们就利用上面得到的结论，做个离散到连续的修正试一试。

这里以二项分布$B(30,0.5)$为例，进行说明。

对于离散的概率分布，我们是可以用条形图来绘制的。

![[b499d7e77d59e154c030cdbb079e6fc4.jpg]]


假如我们假定取值是连续的，可以得到概率直方图。

![[6aa65dc716696780f0da5025eedf48a3.jpg]]

条形图与直方图，大家经常会混淆，所以这里特别贴出关于两者之间的区别供大家参考。

> 条形图与直方图
> - 条形图，主要用于展示分类数据，所以各矩形通常是分开排列的。
> - 直方图，主要用于展示数值型数据，所以各矩形通常是连续排列的。

在回到咱们说的这个小例子，$X\sim B(30,0.5)$,如果想求这样一个概率：
$$P(10\lt X \lt 17)$$

![[6b051d873c62780bc18f9130eaaf00ed.jpg]]

那么，就是要考虑以下几个取值的概率:

![[456c0852dcd1a7a2c8007bde4510c537.jpg]]

也就是，把取值取值$10$到$17$之间每个小矩形的概率加到一起就可以了：
$$\sum_{k=11}^{16}C_{30}^k\frac{1}{2^{30}}=0.6583$$
计算一下，结果是$0.6583$。

很明显这个二项分布的期望和方差分别为$15$和$7.5$。

如果此时，我们直接通过正态分布求概率，则需要对正态分布$N(15,7.5)$的概率密度函数求$(10,17)$区间上的积分：
$$\int_{10}^{17}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx=0.7335$$
但是一比较就会发现，两者结果相差还是很大！

为什么呢？

这是因为用正态分布求概率的时候，也添入了取值包含 10 和 17 的一小部分矩形，多算了一部分，那肯定是要大一些了。

![[d3fe886624f86bae122ed582d5413ccd.jpg]]

所以，这时候需要做一个修正。

之所以用$0.5$,其实就是根据大家自小就熟悉的四舍五入取整计数法来的。

比如这个例子中，用正态近似的时候，可以取区间$(10+0.5,17-0.5)$上的积分
$$\int_{10.5}^{16.5}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx=0.6579$$
这样得到的结果就与二项分布得到的结果很相近啦。

为什么在$10$这个地方加$0.5$，在$17$这个地方是减$0.5$呢？

因为取$(10+0.5,17-0.5)$上的整数的话，根据四舍五入的原则，恰好取得就是$11、12、13、14、15、16$这六个值。

我们再举个例子巩固一下，如果现在换成求概率：
$$P(10\le X\le 17)$$
怎么办呢？

我们希望找到包含$10-17$这八个整数的区间，所以用正态近似的话，就可以求$(10-0.5，17+0.5)$上的积分了

大家可以发现，使用了连续修正后，就能省去计算繁琐的组合数的麻烦啦，这在当年只有计算器还没有计算机的年代，是一个相当大的进步！

